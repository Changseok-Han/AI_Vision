{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder on Iris Dataset \n",
    "* Source : https://www.kaggle.com/shivam1600/autoencoder-on-iris-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "data = pd.read_csv(\"../../data/iris.csv\")\n",
    "data.head()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[['Sepal.Length', 'Sepal.Width',\n",
    "                                                          'Petal.Length', 'Petal.Width']],\n",
    "                                                    data['Species'],test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 28        \n",
      "=================================================================\n",
      "Total params: 138\n",
      "Trainable params: 138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim1 = 6\n",
    "encoding_dim2 = 4\n",
    "encoding_dim3 = 2\n",
    "input_dim = 4\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim1)(input_img)\n",
    "encoded = Dense(encoding_dim2)(encoded)\n",
    "encoded = Dense(encoding_dim3)(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(encoding_dim2)(encoded)\n",
    "decoded = Dense(encoding_dim1)(decoded)\n",
    "decoded = Dense(input_dim)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "#encoder = decoder_layer = autoencoder.layers[3]\n",
    "\n",
    "# create a placeholder for an encoded (2-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim3,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer)\n",
    "opt=RMSprop(lr=0.001)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=opt)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/333\n",
      "135/135 [==============================] - 0s 1ms/sample - loss: 15.8880 - val_loss: 16.8465\n",
      "Epoch 2/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 15.6303 - val_loss: 16.6470\n",
      "Epoch 3/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 15.4440 - val_loss: 16.4382\n",
      "Epoch 4/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 15.2428 - val_loss: 16.1976\n",
      "Epoch 5/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 15.0108 - val_loss: 15.9117\n",
      "Epoch 6/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 14.7386 - val_loss: 15.6112\n",
      "Epoch 7/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 14.4550 - val_loss: 15.3075\n",
      "Epoch 8/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 14.1642 - val_loss: 14.9443\n",
      "Epoch 9/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 13.8192 - val_loss: 14.5615\n",
      "Epoch 10/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 13.4587 - val_loss: 14.1798\n",
      "Epoch 11/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 13.1002 - val_loss: 13.7843\n",
      "Epoch 12/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 12.7259 - val_loss: 13.3362\n",
      "Epoch 13/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 12.3057 - val_loss: 12.8934\n",
      "Epoch 14/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 11.8893 - val_loss: 12.4192\n",
      "Epoch 15/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 11.4459 - val_loss: 11.9479\n",
      "Epoch 16/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 11.0062 - val_loss: 11.4760\n",
      "Epoch 17/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 10.5669 - val_loss: 10.9929\n",
      "Epoch 18/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 10.1157 - val_loss: 10.4855\n",
      "Epoch 19/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 9.6485 - val_loss: 10.0158\n",
      "Epoch 20/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 9.2103 - val_loss: 9.4919\n",
      "Epoch 21/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 8.7278 - val_loss: 8.9953\n",
      "Epoch 22/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 8.2672 - val_loss: 8.4826\n",
      "Epoch 23/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 7.7977 - val_loss: 8.0032\n",
      "Epoch 24/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 7.3579 - val_loss: 7.5164\n",
      "Epoch 25/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 6.9134 - val_loss: 7.0456\n",
      "Epoch 26/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 6.4854 - val_loss: 6.6094\n",
      "Epoch 27/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 6.0878 - val_loss: 6.1854\n",
      "Epoch 28/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 5.7037 - val_loss: 5.7682\n",
      "Epoch 29/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 5.3256 - val_loss: 5.3584\n",
      "Epoch 30/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 4.9563 - val_loss: 4.9816\n",
      "Epoch 31/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 4.6154 - val_loss: 4.6274\n",
      "Epoch 32/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 4.2980 - val_loss: 4.3111\n",
      "Epoch 33/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 4.0131 - val_loss: 3.9837\n",
      "Epoch 34/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 3.7167 - val_loss: 3.6811\n",
      "Epoch 35/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 3.4413 - val_loss: 3.3905\n",
      "Epoch 36/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 3.1749 - val_loss: 3.1098\n",
      "Epoch 37/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 2.9213 - val_loss: 2.8507\n",
      "Epoch 38/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 2.6858 - val_loss: 2.6191\n",
      "Epoch 39/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 2.4759 - val_loss: 2.3833\n",
      "Epoch 40/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 2.2469 - val_loss: 2.1669\n",
      "Epoch 41/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 2.0485 - val_loss: 1.9683\n",
      "Epoch 42/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 1.8689 - val_loss: 1.7856\n",
      "Epoch 43/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 1.7033 - val_loss: 1.6272\n",
      "Epoch 44/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 1.5447 - val_loss: 1.4759\n",
      "Epoch 45/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 1.4015 - val_loss: 1.3402\n",
      "Epoch 46/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 1.2659 - val_loss: 1.2224\n",
      "Epoch 47/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 1.1633 - val_loss: 1.1162\n",
      "Epoch 48/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 1.0690 - val_loss: 1.0246\n",
      "Epoch 49/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.9831 - val_loss: 0.9508\n",
      "Epoch 50/333\n",
      "135/135 [==============================] - 0s 40us/sample - loss: 0.9085 - val_loss: 0.8857\n",
      "Epoch 51/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.8614 - val_loss: 0.8363\n",
      "Epoch 52/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.8108 - val_loss: 0.7972\n",
      "Epoch 53/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.7769 - val_loss: 0.7647\n",
      "Epoch 54/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.7437 - val_loss: 0.7407\n",
      "Epoch 55/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.7200 - val_loss: 0.7176\n",
      "Epoch 56/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.6925 - val_loss: 0.6998\n",
      "Epoch 57/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.6732 - val_loss: 0.6930\n",
      "Epoch 58/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.6582 - val_loss: 0.6955\n",
      "Epoch 59/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.6401 - val_loss: 0.6773\n",
      "Epoch 60/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.6308 - val_loss: 0.6714\n",
      "Epoch 61/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.6222 - val_loss: 0.6603\n",
      "Epoch 62/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.6151 - val_loss: 0.6644\n",
      "Epoch 63/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.6115 - val_loss: 0.7024\n",
      "Epoch 64/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.6156 - val_loss: 0.6512\n",
      "Epoch 65/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.5965 - val_loss: 0.6421\n",
      "Epoch 66/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.5913 - val_loss: 0.6362\n",
      "Epoch 67/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.5855 - val_loss: 0.6192\n",
      "Epoch 68/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.5798 - val_loss: 0.6094\n",
      "Epoch 69/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.5754 - val_loss: 0.6252\n",
      "Epoch 70/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.5708 - val_loss: 0.6267\n",
      "Epoch 71/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.5667 - val_loss: 0.6120\n",
      "Epoch 72/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.5613 - val_loss: 0.6473\n",
      "Epoch 73/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.5664 - val_loss: 0.5876\n",
      "Epoch 74/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.5492 - val_loss: 0.5612\n",
      "Epoch 75/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.5547 - val_loss: 0.5839\n",
      "Epoch 76/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.5393 - val_loss: 0.5570\n",
      "Epoch 77/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.5358 - val_loss: 0.5581\n",
      "Epoch 78/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.5266 - val_loss: 0.5525\n",
      "Epoch 79/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.5240 - val_loss: 0.5499\n",
      "Epoch 80/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.5188 - val_loss: 0.5355\n",
      "Epoch 81/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.5172 - val_loss: 0.5690\n",
      "Epoch 82/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.5161 - val_loss: 0.5521\n",
      "Epoch 83/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.5095 - val_loss: 0.5671\n",
      "Epoch 84/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.5122 - val_loss: 0.5537\n",
      "Epoch 85/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.5079 - val_loss: 0.5629\n",
      "Epoch 86/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.5065 - val_loss: 0.5067\n",
      "Epoch 87/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.4971 - val_loss: 0.5152\n",
      "Epoch 88/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.4906 - val_loss: 0.5234\n",
      "Epoch 89/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.4858 - val_loss: 0.5225\n",
      "Epoch 90/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.4861 - val_loss: 0.5145\n",
      "Epoch 91/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.4772 - val_loss: 0.4883\n",
      "Epoch 92/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.4731 - val_loss: 0.4946\n",
      "Epoch 93/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.4691 - val_loss: 0.4999\n",
      "Epoch 94/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.4652 - val_loss: 0.4765\n",
      "Epoch 95/333\n",
      "135/135 [==============================] - 0s 35us/sample - loss: 0.4583 - val_loss: 0.4945\n",
      "Epoch 96/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.4582 - val_loss: 0.4595\n",
      "Epoch 97/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.4550 - val_loss: 0.4517\n",
      "Epoch 98/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.4506 - val_loss: 0.4659\n",
      "Epoch 99/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.4424 - val_loss: 0.4458\n",
      "Epoch 100/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.4384 - val_loss: 0.4397\n",
      "Epoch 101/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.4342 - val_loss: 0.4504\n",
      "Epoch 102/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.4248 - val_loss: 0.4341\n",
      "Epoch 103/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.4179 - val_loss: 0.4307\n",
      "Epoch 104/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.4130 - val_loss: 0.4459\n",
      "Epoch 105/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.4151 - val_loss: 0.4062\n",
      "Epoch 106/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.4092 - val_loss: 0.4141\n",
      "Epoch 107/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.3964 - val_loss: 0.4165\n",
      "Epoch 108/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.3928 - val_loss: 0.4252\n",
      "Epoch 109/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.3904 - val_loss: 0.4053\n",
      "Epoch 110/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.3827 - val_loss: 0.3842\n",
      "Epoch 111/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.3762 - val_loss: 0.4123\n",
      "Epoch 112/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.3761 - val_loss: 0.4351\n",
      "Epoch 113/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.3820 - val_loss: 0.3657\n",
      "Epoch 114/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.3555 - val_loss: 0.3681\n",
      "Epoch 115/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.3536 - val_loss: 0.3743\n",
      "Epoch 116/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.3474 - val_loss: 0.3991\n",
      "Epoch 117/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.3516 - val_loss: 0.3432\n",
      "Epoch 118/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.3283 - val_loss: 0.3205\n",
      "Epoch 119/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.3260 - val_loss: 0.3233\n",
      "Epoch 120/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.3158 - val_loss: 0.3109\n",
      "Epoch 121/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.3075 - val_loss: 0.3007\n",
      "Epoch 122/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.3031 - val_loss: 0.2932\n",
      "Epoch 123/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.2933 - val_loss: 0.2834\n",
      "Epoch 124/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.2882 - val_loss: 0.2711\n",
      "Epoch 125/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.2879 - val_loss: 0.2817\n",
      "Epoch 126/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.2727 - val_loss: 0.2677\n",
      "Epoch 127/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.2666 - val_loss: 0.2728\n",
      "Epoch 128/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.2588 - val_loss: 0.2527\n",
      "Epoch 129/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.2521 - val_loss: 0.2466\n",
      "Epoch 130/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.2418 - val_loss: 0.2419\n",
      "Epoch 131/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.2362 - val_loss: 0.2253\n",
      "Epoch 132/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.2276 - val_loss: 0.2216\n",
      "Epoch 133/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.2187 - val_loss: 0.2219\n",
      "Epoch 134/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.2125 - val_loss: 0.2210\n",
      "Epoch 135/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.2077 - val_loss: 0.2181\n",
      "Epoch 136/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.2037 - val_loss: 0.1807\n",
      "Epoch 137/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.1891 - val_loss: 0.1958\n",
      "Epoch 138/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.1843 - val_loss: 0.1818\n",
      "Epoch 139/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.1776 - val_loss: 0.1876\n",
      "Epoch 140/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.1770 - val_loss: 0.1679\n",
      "Epoch 141/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.1676 - val_loss: 0.1900\n",
      "Epoch 142/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.1683 - val_loss: 0.1419\n",
      "Epoch 143/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.1543 - val_loss: 0.1339\n",
      "Epoch 144/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.1479 - val_loss: 0.1286\n",
      "Epoch 145/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.1410 - val_loss: 0.1233\n",
      "Epoch 146/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.1332 - val_loss: 0.1216\n",
      "Epoch 147/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.1289 - val_loss: 0.1233\n",
      "Epoch 148/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.1243 - val_loss: 0.1137\n",
      "Epoch 149/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.1168 - val_loss: 0.0989\n",
      "Epoch 150/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.1149 - val_loss: 0.0960\n",
      "Epoch 151/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.1082 - val_loss: 0.0879\n",
      "Epoch 152/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.1047 - val_loss: 0.0845\n",
      "Epoch 153/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.1070 - val_loss: 0.0855\n",
      "Epoch 154/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0989 - val_loss: 0.0918\n",
      "Epoch 155/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0927 - val_loss: 0.0742\n",
      "Epoch 156/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0983 - val_loss: 0.0748\n",
      "Epoch 157/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0866 - val_loss: 0.0697\n",
      "Epoch 158/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0832 - val_loss: 0.0635\n",
      "Epoch 159/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0782 - val_loss: 0.0644\n",
      "Epoch 160/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0739 - val_loss: 0.0723\n",
      "Epoch 161/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0737 - val_loss: 0.0607\n",
      "Epoch 162/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0687 - val_loss: 0.0643\n",
      "Epoch 163/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.0682 - val_loss: 0.0728\n",
      "Epoch 164/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0699 - val_loss: 0.0586\n",
      "Epoch 165/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0658 - val_loss: 0.0823\n",
      "Epoch 166/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0742 - val_loss: 0.0590\n",
      "Epoch 167/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0631 - val_loss: 0.0473\n",
      "Epoch 168/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0593 - val_loss: 0.0392\n",
      "Epoch 169/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0580 - val_loss: 0.0432\n",
      "Epoch 170/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0545 - val_loss: 0.0365\n",
      "Epoch 171/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0553 - val_loss: 0.0430\n",
      "Epoch 172/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0502 - val_loss: 0.0361\n",
      "Epoch 173/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0512 - val_loss: 0.0400\n",
      "Epoch 174/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0508 - val_loss: 0.0343\n",
      "Epoch 175/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0483 - val_loss: 0.0336\n",
      "Epoch 176/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0520 - val_loss: 0.0335\n",
      "Epoch 177/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0471 - val_loss: 0.0346\n",
      "Epoch 178/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0441 - val_loss: 0.0431\n",
      "Epoch 179/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0476 - val_loss: 0.0579\n",
      "Epoch 180/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0519 - val_loss: 0.0382\n",
      "Epoch 181/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0428 - val_loss: 0.0343\n",
      "Epoch 182/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0415 - val_loss: 0.0327\n",
      "Epoch 183/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0409 - val_loss: 0.0571\n",
      "Epoch 184/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0520 - val_loss: 0.0415\n",
      "Epoch 185/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0425 - val_loss: 0.0285\n",
      "Epoch 186/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0392 - val_loss: 0.0271\n",
      "Epoch 187/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0389 - val_loss: 0.0373\n",
      "Epoch 188/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0415 - val_loss: 0.0351\n",
      "Epoch 189/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0421 - val_loss: 0.0270\n",
      "Epoch 190/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0407 - val_loss: 0.0240\n",
      "Epoch 191/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0426 - val_loss: 0.0267\n",
      "Epoch 192/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0507 - val_loss: 0.0243\n",
      "Epoch 193/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0374 - val_loss: 0.0314\n",
      "Epoch 194/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 195/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0354 - val_loss: 0.0249\n",
      "Epoch 196/333\n",
      "135/135 [==============================] - 0s 35us/sample - loss: 0.0382 - val_loss: 0.0318\n",
      "Epoch 197/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0356 - val_loss: 0.0250\n",
      "Epoch 198/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0421 - val_loss: 0.0265\n",
      "Epoch 199/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0473 - val_loss: 0.0253\n",
      "Epoch 200/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0374 - val_loss: 0.0302\n",
      "Epoch 201/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0349 - val_loss: 0.0331\n",
      "Epoch 202/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0368 - val_loss: 0.0349\n",
      "Epoch 203/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0368 - val_loss: 0.0350\n",
      "Epoch 204/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0373 - val_loss: 0.0364\n",
      "Epoch 205/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0372 - val_loss: 0.0406\n",
      "Epoch 206/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0400 - val_loss: 0.0550\n",
      "Epoch 207/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0480 - val_loss: 0.0424\n",
      "Epoch 208/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0396 - val_loss: 0.0265\n",
      "Epoch 209/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0335 - val_loss: 0.0358\n",
      "Epoch 210/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0378 - val_loss: 0.0387\n",
      "Epoch 211/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0378 - val_loss: 0.0317\n",
      "Epoch 212/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0353 - val_loss: 0.0361\n",
      "Epoch 213/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0360 - val_loss: 0.0310\n",
      "Epoch 214/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0349 - val_loss: 0.0360\n",
      "Epoch 215/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0372 - val_loss: 0.0482\n",
      "Epoch 216/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0443 - val_loss: 0.0366\n",
      "Epoch 217/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0361 - val_loss: 0.0297\n",
      "Epoch 218/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0343 - val_loss: 0.0463\n",
      "Epoch 219/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0417 - val_loss: 0.0441\n",
      "Epoch 220/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0412 - val_loss: 0.0375\n",
      "Epoch 221/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0386 - val_loss: 0.0288\n",
      "Epoch 222/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0354 - val_loss: 0.0294\n",
      "Epoch 223/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0352 - val_loss: 0.0382\n",
      "Epoch 224/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0372 - val_loss: 0.0292\n",
      "Epoch 225/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0337 - val_loss: 0.0316\n",
      "Epoch 226/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0338 - val_loss: 0.0299\n",
      "Epoch 227/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0344 - val_loss: 0.0409\n",
      "Epoch 228/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0384 - val_loss: 0.0538\n",
      "Epoch 229/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0459 - val_loss: 0.0418\n",
      "Epoch 230/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.0387 - val_loss: 0.0458\n",
      "Epoch 231/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0407 - val_loss: 0.0413\n",
      "Epoch 232/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0388 - val_loss: 0.0329\n",
      "Epoch 233/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0344 - val_loss: 0.0269\n",
      "Epoch 234/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0331 - val_loss: 0.0265\n",
      "Epoch 235/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0328 - val_loss: 0.0358\n",
      "Epoch 236/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0359 - val_loss: 0.0330\n",
      "Epoch 237/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0338 - val_loss: 0.0286\n",
      "Epoch 238/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0336 - val_loss: 0.0340\n",
      "Epoch 239/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0352 - val_loss: 0.0437\n",
      "Epoch 240/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0395 - val_loss: 0.0373\n",
      "Epoch 241/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.0362 - val_loss: 0.0419\n",
      "Epoch 242/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 243/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0337 - val_loss: 0.0278\n",
      "Epoch 244/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0331 - val_loss: 0.0320\n",
      "Epoch 245/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0343 - val_loss: 0.0277\n",
      "Epoch 246/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0358 - val_loss: 0.0253\n",
      "Epoch 247/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0329 - val_loss: 0.0238\n",
      "Epoch 248/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0350 - val_loss: 0.0228\n",
      "Epoch 249/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0359 - val_loss: 0.0216\n",
      "Epoch 250/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0353 - val_loss: 0.0240\n",
      "Epoch 251/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0360 - val_loss: 0.0287\n",
      "Epoch 252/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 253/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0327 - val_loss: 0.0248\n",
      "Epoch 254/333\n",
      "135/135 [==============================] - 0s 38us/sample - loss: 0.0362 - val_loss: 0.0242\n",
      "Epoch 255/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0394 - val_loss: 0.0235\n",
      "Epoch 256/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0329 - val_loss: 0.0245\n",
      "Epoch 257/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.0345 - val_loss: 0.0232\n",
      "Epoch 258/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0374 - val_loss: 0.0239\n",
      "Epoch 259/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0366 - val_loss: 0.0271\n",
      "Epoch 260/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0323 - val_loss: 0.0405\n",
      "Epoch 261/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0378 - val_loss: 0.0467\n",
      "Epoch 262/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0411 - val_loss: 0.0385\n",
      "Epoch 263/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0375 - val_loss: 0.0320\n",
      "Epoch 264/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.0345 - val_loss: 0.0283\n",
      "Epoch 265/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0338 - val_loss: 0.0309\n",
      "Epoch 266/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0333 - val_loss: 0.0426\n",
      "Epoch 267/333\n",
      "135/135 [==============================] - 0s 36us/sample - loss: 0.0380 - val_loss: 0.0307\n",
      "Epoch 268/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0335 - val_loss: 0.0274\n",
      "Epoch 269/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0422 - val_loss: 0.0279\n",
      "Epoch 270/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0395 - val_loss: 0.0259\n",
      "Epoch 271/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0325 - val_loss: 0.0229\n",
      "Epoch 272/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0351 - val_loss: 0.0275\n",
      "Epoch 273/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0355 - val_loss: 0.0227\n",
      "Epoch 274/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0356 - val_loss: 0.0256\n",
      "Epoch 275/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0318 - val_loss: 0.0253\n",
      "Epoch 276/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0347 - val_loss: 0.0323\n",
      "Epoch 277/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0329 - val_loss: 0.0245\n",
      "Epoch 278/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0385 - val_loss: 0.0234\n",
      "Epoch 279/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0394 - val_loss: 0.0270\n",
      "Epoch 280/333\n",
      "135/135 [==============================] - 0s 35us/sample - loss: 0.0411 - val_loss: 0.0255\n",
      "Epoch 281/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0321 - val_loss: 0.0243\n",
      "Epoch 282/333\n",
      "135/135 [==============================] - 0s 27us/sample - loss: 0.0329 - val_loss: 0.0259\n",
      "Epoch 283/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0350 - val_loss: 0.0243\n",
      "Epoch 284/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0395 - val_loss: 0.0220\n",
      "Epoch 285/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0375 - val_loss: 0.0211\n",
      "Epoch 286/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0327 - val_loss: 0.0237\n",
      "Epoch 287/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0320 - val_loss: 0.0253\n",
      "Epoch 288/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0341 - val_loss: 0.0429\n",
      "Epoch 289/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0436 - val_loss: 0.0320\n",
      "Epoch 290/333\n",
      "135/135 [==============================] - 0s 36us/sample - loss: 0.0340 - val_loss: 0.0288\n",
      "Epoch 291/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0333 - val_loss: 0.0274\n",
      "Epoch 292/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0329 - val_loss: 0.0246\n",
      "Epoch 293/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0322 - val_loss: 0.0311\n",
      "Epoch 294/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0336 - val_loss: 0.0293\n",
      "Epoch 295/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0332 - val_loss: 0.0428\n",
      "Epoch 296/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0389 - val_loss: 0.0259\n",
      "Epoch 297/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0332 - val_loss: 0.0470\n",
      "Epoch 298/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0413 - val_loss: 0.0308\n",
      "Epoch 299/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0328 - val_loss: 0.0266\n",
      "Epoch 300/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.0355 - val_loss: 0.0278\n",
      "Epoch 301/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0320 - val_loss: 0.0286\n",
      "Epoch 302/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0323 - val_loss: 0.0316\n",
      "Epoch 303/333\n",
      "135/135 [==============================] - 0s 34us/sample - loss: 0.0346 - val_loss: 0.0547\n",
      "Epoch 304/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0463 - val_loss: 0.0289\n",
      "Epoch 305/333\n",
      "135/135 [==============================] - 0s 35us/sample - loss: 0.0333 - val_loss: 0.0304\n",
      "Epoch 306/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0334 - val_loss: 0.0329\n",
      "Epoch 307/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0334 - val_loss: 0.0328\n",
      "Epoch 308/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0331 - val_loss: 0.0320\n",
      "Epoch 309/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0359 - val_loss: 0.0275\n",
      "Epoch 310/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0347 - val_loss: 0.0275\n",
      "Epoch 311/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0443 - val_loss: 0.0256\n",
      "Epoch 312/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0327 - val_loss: 0.0224\n",
      "Epoch 313/333\n",
      "135/135 [==============================] - 0s 35us/sample - loss: 0.0316 - val_loss: 0.0255\n",
      "Epoch 314/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0321 - val_loss: 0.0298\n",
      "Epoch 315/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0360 - val_loss: 0.0266\n",
      "Epoch 316/333\n",
      "135/135 [==============================] - 0s 32us/sample - loss: 0.0315 - val_loss: 0.0315\n",
      "Epoch 317/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0341 - val_loss: 0.0309\n",
      "Epoch 318/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0334 - val_loss: 0.0337\n",
      "Epoch 319/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0358 - val_loss: 0.0490\n",
      "Epoch 320/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0427 - val_loss: 0.0329\n",
      "Epoch 321/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0344 - val_loss: 0.0265\n",
      "Epoch 322/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0319 - val_loss: 0.0356\n",
      "Epoch 323/333\n",
      "135/135 [==============================] - 0s 28us/sample - loss: 0.0375 - val_loss: 0.0342\n",
      "Epoch 324/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0354 - val_loss: 0.0441\n",
      "Epoch 325/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0395 - val_loss: 0.0301\n",
      "Epoch 326/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0334 - val_loss: 0.0355\n",
      "Epoch 327/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0346 - val_loss: 0.0371\n",
      "Epoch 328/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0359 - val_loss: 0.0248\n",
      "Epoch 329/333\n",
      "135/135 [==============================] - 0s 29us/sample - loss: 0.0326 - val_loss: 0.0234\n",
      "Epoch 330/333\n",
      "135/135 [==============================] - 0s 38us/sample - loss: 0.0324 - val_loss: 0.0471\n",
      "Epoch 331/333\n",
      "135/135 [==============================] - 0s 31us/sample - loss: 0.0401 - val_loss: 0.0258\n",
      "Epoch 332/333\n",
      "135/135 [==============================] - 0s 33us/sample - loss: 0.0322 - val_loss: 0.0307\n",
      "Epoch 333/333\n",
      "135/135 [==============================] - 0s 30us/sample - loss: 0.0335 - val_loss: 0.0314\n",
      "Original Datapoints :\n",
      "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
      "14            5.8          4.0           1.2          0.2\n",
      "98            5.1          2.5           3.0          1.1\n",
      "75            6.6          3.0           4.4          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "131           7.9          3.8           6.4          2.0\n",
      "56            6.3          3.3           4.7          1.6\n",
      "141           6.9          3.1           5.1          2.3\n",
      "44            5.1          3.8           1.9          0.4\n",
      "29            4.7          3.2           1.6          0.2\n",
      "120           6.9          3.2           5.7          2.3\n",
      "94            5.6          2.7           4.2          1.3\n",
      "5             5.4          3.9           1.7          0.4\n",
      "102           7.1          3.0           5.9          2.1\n",
      "51            6.4          3.2           4.5          1.5\n",
      "78            6.0          2.9           4.5          1.5\n",
      "Reconstructed Datapoints :\n",
      "[[5.4370937  3.9737885  1.3970298  0.04028982]\n",
      " [5.0948315  2.7547464  3.1840901  0.9529672 ]\n",
      " [6.249125   3.205132   4.578007   1.4042809 ]\n",
      " [5.2651377  3.775203   1.4559172  0.09982395]\n",
      " [7.5676236  3.6243625  6.3632455  2.011601  ]\n",
      " [6.2962813  3.1943636  4.69408    1.450839  ]\n",
      " [6.63901    3.131607   5.5062404  1.7742653 ]\n",
      " [5.2288904  3.573513   1.7923155  0.2664603 ]\n",
      " [4.773367   3.2477827  1.5422192  0.23103213]\n",
      " [6.801309   3.1067836  5.8809175  1.9227054 ]\n",
      " [5.6568303  2.820303   4.1743684  1.3209045 ]\n",
      " [5.3513737  3.7281783  1.7235848  0.21131527]\n",
      " [6.850673   3.0760036  6.0419655  1.9902492 ]\n",
      " [6.256286   3.214242   4.573853   1.4009922 ]\n",
      " [5.9805765  2.9631839  4.5317545  1.4315195 ]]\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=333,\n",
    "                batch_size=123,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "               callbacks=[])\n",
    "\n",
    "# encode and decode some data points\n",
    "# note that we take them from the *test* set\n",
    "encoded_datapoints = encoder.predict(x_test)\n",
    "decoded_datapoints = decoder.predict(encoded_datapoints)\n",
    "\n",
    "print('Original Datapoints :')\n",
    "print(x_test)\n",
    "print('Reconstructed Datapoints :')\n",
    "print(decoded_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoder.predict(x_test[['Sepal.Length', 'Sepal.Width',\n",
    "                                        'Petal.Length', 'Petal.Width']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoded Dataset(reconstruncted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_dataset=decoder.predict(encoded_dataset)\n",
    "plt.scatter(decoded_dataset[:,2], decoded_dataset[:,3], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orignal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_test['Petal.Length'], x_test['Petal.Width'],c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
